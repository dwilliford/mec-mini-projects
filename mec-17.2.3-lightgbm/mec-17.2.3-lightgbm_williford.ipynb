{"cells":[{"cell_type":"code","source":["import os\nimport sys\n\n\nimport pyspark\nfrom pyspark.ml import PipelineModel\nfrom pyspark.ml.feature import FeatureHasher\nimport papermill as pm\nimport scrapbook as sb\n\nfrom recommenders.utils.notebook_utils import is_databricks\nfrom recommenders.utils.spark_utils import start_or_get_spark\nfrom recommenders.datasets.criteo import load_spark_df\nfrom recommenders.datasets.spark_splitters import spark_random_split\n\n# Setup MML Spark\n#from recommenders.utils.spark_utils import MMLSPARK_REPO, MMLSPARK_PACKAGE\n#print(MMLSPARK_REPO)\n#print(MMLSPARK_PACKAGE)\n#packages = [MMLSPARK_PACKAGE]\n#repos = [MMLSPARK_REPO]\n#spark = start_or_get_spark(packages=packages, repositories=repos)\n#dbutils = None\n#print(\"MMLSpark version: {} from {}\".format(MMLSPARK_PACKAGE,MMLSPARK_REPO))\n#from mmlspark.train import ComputeModelStatistics\n#from mmlspark.lightgbm import LightGBMClassifier\n\n# Synapse.ml is the new version of mml\nimport synapse.ml\nfrom synapse.ml.train import ComputeModelStatistics\nfrom synapse.ml.lightgbm import LightGBMClassifier\n\nprint(\"System version: {}\".format(sys.version))\nprint(\"PySpark version: {}\".format(pyspark.version.__version__))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ba582bbe-ae94-43f8-92d8-e16d0b480f4e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"System version: 3.8.10 (default, Nov 26 2021, 20:14:08) \n[GCC 9.3.0]\nPySpark version: 3.1.2\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["System version: 3.8.10 (default, Nov 26 2021, 20:14:08) \n[GCC 9.3.0]\nPySpark version: 3.1.2\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["#!pip list"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"357ea639-38a7-4663-b7b2-1d18dceb40af"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Package             Version\r\n------------------- --------------------\r\nansiwrap            0.8.4\r\nappdirs             1.4.4\r\nargon2-cffi         20.1.0\r\nasync-generator     1.10\r\nattrs               20.3.0\r\nbackcall            0.2.0\r\nbleach              3.3.0\r\nboto3               1.16.7\r\nbotocore            1.19.7\r\nBottleneck          1.3.2\r\ncategory-encoders   1.3.0\r\ncertifi             2020.12.5\r\ncffi                1.14.5\r\nchardet             4.0.0\r\nclick               8.0.3\r\ncornac              1.14.1\r\ncycler              0.10.0\r\nCython              0.29.23\r\ndbus-python         1.2.16\r\ndecorator           5.0.6\r\ndefusedxml          0.7.1\r\ndistlib             0.3.2\r\ndistro              1.4.0\r\ndistro-info         0.23ubuntu1\r\nentrypoints         0.3\r\nfacets-overview     1.0.0\r\nfilelock            3.0.12\r\nhuggingface-hub     0.4.0\r\nhypothesis          6.36.1\r\nidna                2.10\r\nipykernel           5.3.4\r\nipython             7.22.0\r\nipython-genutils    0.2.0\r\nipywidgets          7.6.3\r\njedi                0.17.2\r\nJinja2              2.11.3\r\njmespath            0.10.0\r\njoblib              1.0.1\r\njsonschema          3.2.0\r\njupyter-client      6.1.12\r\njupyter-core        4.7.1\r\njupyterlab-pygments 0.1.2\r\njupyterlab-widgets  1.0.0\r\nkiwisolver          1.3.1\r\nkoalas              1.8.1\r\nlightfm             1.16\r\nlightgbm            3.3.2\r\nllvmlite            0.38.0\r\nMarkupSafe          1.1.1\r\nmatplotlib          3.4.2\r\nmemory-profiler     0.60.0\r\nmistune             0.8.4\r\nmmlspark            0.0.11111111\r\nmpmath              1.2.1\r\nmypy-extensions     0.4.3\r\nnbclient            0.5.3\r\nnbconvert           6.0.7\r\nnbformat            5.1.3\r\nnest-asyncio        1.5.1\r\nnltk                3.6.7\r\nnotebook            6.3.0\r\nnumba               0.55.1\r\nnumpy               1.19.2\r\npackaging           20.9\r\npandas              1.2.4\r\npandera             0.8.1\r\npandocfilters       1.4.3\r\npapermill           2.3.4\r\nparso               0.7.0\r\npatsy               0.5.1\r\npexpect             4.8.0\r\npickleshare         0.7.5\r\nPillow              8.2.0\r\npip                 21.0.1\r\nplotly              5.1.0\r\npowerlaw            1.5\r\nprometheus-client   0.10.1\r\nprompt-toolkit      3.0.17\r\nprotobuf            3.17.2\r\npsutil              5.9.0\r\npsycopg2            2.8.5\r\nptyprocess          0.7.0\r\npy4j                0.10.9.3\r\npyarrow             4.0.0\r\npycparser           2.20\r\npydocumentdb        2.3.5\r\nPygments            2.8.1\r\nPyGObject           3.36.0\r\npyparsing           2.4.7\r\npyrsistent          0.17.3\r\npyspark             3.2.1\r\npython-apt          2.0.0+ubuntu0.20.4.6\r\npython-dateutil     2.8.1\r\npytz                2020.5\r\nPyYAML              5.4.1\r\npyzmq               20.0.0\r\nrecommenders        1.0.0\r\nregex               2022.1.18\r\nrequests            2.25.1\r\nrequests-unixsocket 0.2.0\r\nretrying            1.3.3\r\ns3transfer          0.3.7\r\nsacremoses          0.0.47\r\nscikit-learn        0.24.1\r\nscipy               1.6.2\r\nscrapbook           0.5.0\r\nseaborn             0.11.1\r\nSend2Trash          1.5.0\r\nsetuptools          52.0.0\r\nsix                 1.15.0\r\nsortedcontainers    2.4.0\r\nssh-import-id       5.10\r\nstatsmodels         0.12.2\r\nsynapseml           0.9.5\r\ntenacity            8.0.1\r\nterminado           0.9.4\r\ntestpath            0.4.4\r\ntextwrap3           0.9.2\r\nthreadpoolctl       2.1.0\r\ntokenizers          0.11.4\r\ntornado             6.1\r\ntqdm                4.62.3\r\ntraitlets           5.0.5\r\ntransformers        4.16.2\r\ntyping-extensions   4.0.1\r\ntyping-inspect      0.7.1\r\nunattended-upgrades 0.1\r\nurllib3             1.25.11\r\nvirtualenv          20.4.1\r\nwcwidth             0.2.5\r\nwebencodings        0.5.1\r\nwheel               0.36.2\r\nwidgetsnbextension  3.5.1\r\nwrapt               1.13.3\r\n\u001B[33mWARNING: You are using pip version 21.0.1; however, version 22.0.3 is available.\r\nYou should consider upgrading via the '/databricks/python3/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Package             Version\r\n------------------- --------------------\r\nansiwrap            0.8.4\r\nappdirs             1.4.4\r\nargon2-cffi         20.1.0\r\nasync-generator     1.10\r\nattrs               20.3.0\r\nbackcall            0.2.0\r\nbleach              3.3.0\r\nboto3               1.16.7\r\nbotocore            1.19.7\r\nBottleneck          1.3.2\r\ncategory-encoders   1.3.0\r\ncertifi             2020.12.5\r\ncffi                1.14.5\r\nchardet             4.0.0\r\nclick               8.0.3\r\ncornac              1.14.1\r\ncycler              0.10.0\r\nCython              0.29.23\r\ndbus-python         1.2.16\r\ndecorator           5.0.6\r\ndefusedxml          0.7.1\r\ndistlib             0.3.2\r\ndistro              1.4.0\r\ndistro-info         0.23ubuntu1\r\nentrypoints         0.3\r\nfacets-overview     1.0.0\r\nfilelock            3.0.12\r\nhuggingface-hub     0.4.0\r\nhypothesis          6.36.1\r\nidna                2.10\r\nipykernel           5.3.4\r\nipython             7.22.0\r\nipython-genutils    0.2.0\r\nipywidgets          7.6.3\r\njedi                0.17.2\r\nJinja2              2.11.3\r\njmespath            0.10.0\r\njoblib              1.0.1\r\njsonschema          3.2.0\r\njupyter-client      6.1.12\r\njupyter-core        4.7.1\r\njupyterlab-pygments 0.1.2\r\njupyterlab-widgets  1.0.0\r\nkiwisolver          1.3.1\r\nkoalas              1.8.1\r\nlightfm             1.16\r\nlightgbm            3.3.2\r\nllvmlite            0.38.0\r\nMarkupSafe          1.1.1\r\nmatplotlib          3.4.2\r\nmemory-profiler     0.60.0\r\nmistune             0.8.4\r\nmmlspark            0.0.11111111\r\nmpmath              1.2.1\r\nmypy-extensions     0.4.3\r\nnbclient            0.5.3\r\nnbconvert           6.0.7\r\nnbformat            5.1.3\r\nnest-asyncio        1.5.1\r\nnltk                3.6.7\r\nnotebook            6.3.0\r\nnumba               0.55.1\r\nnumpy               1.19.2\r\npackaging           20.9\r\npandas              1.2.4\r\npandera             0.8.1\r\npandocfilters       1.4.3\r\npapermill           2.3.4\r\nparso               0.7.0\r\npatsy               0.5.1\r\npexpect             4.8.0\r\npickleshare         0.7.5\r\nPillow              8.2.0\r\npip                 21.0.1\r\nplotly              5.1.0\r\npowerlaw            1.5\r\nprometheus-client   0.10.1\r\nprompt-toolkit      3.0.17\r\nprotobuf            3.17.2\r\npsutil              5.9.0\r\npsycopg2            2.8.5\r\nptyprocess          0.7.0\r\npy4j                0.10.9.3\r\npyarrow             4.0.0\r\npycparser           2.20\r\npydocumentdb        2.3.5\r\nPygments            2.8.1\r\nPyGObject           3.36.0\r\npyparsing           2.4.7\r\npyrsistent          0.17.3\r\npyspark             3.2.1\r\npython-apt          2.0.0+ubuntu0.20.4.6\r\npython-dateutil     2.8.1\r\npytz                2020.5\r\nPyYAML              5.4.1\r\npyzmq               20.0.0\r\nrecommenders        1.0.0\r\nregex               2022.1.18\r\nrequests            2.25.1\r\nrequests-unixsocket 0.2.0\r\nretrying            1.3.3\r\ns3transfer          0.3.7\r\nsacremoses          0.0.47\r\nscikit-learn        0.24.1\r\nscipy               1.6.2\r\nscrapbook           0.5.0\r\nseaborn             0.11.1\r\nSend2Trash          1.5.0\r\nsetuptools          52.0.0\r\nsix                 1.15.0\r\nsortedcontainers    2.4.0\r\nssh-import-id       5.10\r\nstatsmodels         0.12.2\r\nsynapseml           0.9.5\r\ntenacity            8.0.1\r\nterminado           0.9.4\r\ntestpath            0.4.4\r\ntextwrap3           0.9.2\r\nthreadpoolctl       2.1.0\r\ntokenizers          0.11.4\r\ntornado             6.1\r\ntqdm                4.62.3\r\ntraitlets           5.0.5\r\ntransformers        4.16.2\r\ntyping-extensions   4.0.1\r\ntyping-inspect      0.7.1\r\nunattended-upgrades 0.1\r\nurllib3             1.25.11\r\nvirtualenv          20.4.1\r\nwcwidth             0.2.5\r\nwebencodings        0.5.1\r\nwheel               0.36.2\r\nwidgetsnbextension  3.5.1\r\nwrapt               1.13.3\r\n\u001B[33mWARNING: You are using pip version 21.0.1; however, version 22.0.3 is available.\r\nYou should consider upgrading via the '/databricks/python3/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Criteo data size, it can be \"sample\" or \"full\"\nDATA_SIZE = \"sample\"\n\n# LightGBM parameters\n# More details on parameters: https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html\nNUM_LEAVES = 32\nNUM_ITERATIONS = 50\nLEARNING_RATE = 0.1\nFEATURE_FRACTION = 0.8\nEARLY_STOPPING_ROUND = 10\n\n# Model name\nMODEL_NAME = 'lightgbm_criteo.mml'"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3109c464-ee75-4ede-b8e5-73981445b5f1"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql import SparkSession\nspark = SparkSession.builder.appName(\"SparkSessionLightGBM\").getOrCreate()\n#spark.version()\n\nfrom pyspark.dbutils import DBUtils\ndbutils = DBUtils(spark)\n\ndbutils.widgets.help()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e81ffbc1-a734-458c-be50-c0253ea0356b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class = \"ansiout\"><b>dbutils.widgets</b> provides utilities for working with notebook widgets. You can create\ndifferent types of widgets and get their bound value.\n\nFor more info about a method, use <b>dbutils.widgets.help(\"methodName\")</b>.\n    <h3></h3><b>combobox(name: String, defaultValue: String, choices: Seq, label: String): void</b> -> Creates a combobox input widget with a given name, default value and choices<br /><b>dropdown(name: String, defaultValue: String, choices: Seq, label: String): void</b> -> Creates a dropdown input widget a with given name, default value and choices<br /><b>get(name: String): String</b> -> Retrieves current value of an input widget<br /><b>getArgument(name: String, optional: String): String</b> -> (DEPRECATED) Equivalent to get<br /><b>multiselect(name: String, defaultValue: String, choices: Seq, label: String): void</b> -> Creates a multiselect input widget with a given name, default value and choices<br /><b>remove(name: String): void</b> -> Removes an input widget from the notebook<br /><b>removeAll: void</b> -> Removes all widgets in the notebook<br /><b>text(name: String, defaultValue: String, label: String): void</b> -> Creates a text input widget with a given name and default value<br /><br /></div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div class = \"ansiout\"><b>dbutils.widgets</b> provides utilities for working with notebook widgets. You can create\ndifferent types of widgets and get their bound value.\n\nFor more info about a method, use <b>dbutils.widgets.help(\"methodName\")</b>.\n    <h3></h3><b>combobox(name: String, defaultValue: String, choices: Seq, label: String): void</b> -> Creates a combobox input widget with a given name, default value and choices<br /><b>dropdown(name: String, defaultValue: String, choices: Seq, label: String): void</b> -> Creates a dropdown input widget a with given name, default value and choices<br /><b>get(name: String): String</b> -> Retrieves current value of an input widget<br /><b>getArgument(name: String, optional: String): String</b> -> (DEPRECATED) Equivalent to get<br /><b>multiselect(name: String, defaultValue: String, choices: Seq, label: String): void</b> -> Creates a multiselect input widget with a given name, default value and choices<br /><b>remove(name: String): void</b> -> Removes an input widget from the notebook<br /><b>removeAll: void</b> -> Removes all widgets in the notebook<br /><b>text(name: String, defaultValue: String, label: String): void</b> -> Creates a text input widget with a given name and default value<br /><br /></div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["raw_data = load_spark_df(size=DATA_SIZE, spark=spark, dbutils=dbutils)\n# visualize data\nraw_data.limit(2).toPandas().head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"eba92245-5000-4360-8305-5aaf9bfeebd1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"\r  0%|          | 0.00/8.58k [00:00<?, ?KB/s]\r  0%|          | 13.0/8.58k [00:00<01:19, 108KB/s]\r  0%|          | 41.0/8.58k [00:00<00:42, 199KB/s]\r  1%|          | 68.0/8.58k [00:00<00:52, 163KB/s]\r  1%|          | 98.0/8.58k [00:00<00:48, 175KB/s]\r  2%|▏         | 140/8.58k [00:00<00:40, 210KB/s] \r  2%|▏         | 173/8.58k [00:00<00:39, 211KB/s]\r  2%|▏         | 210/8.58k [00:01<00:37, 221KB/s]\r  3%|▎         | 253/8.58k [00:01<00:34, 239KB/s]\r  3%|▎         | 286/8.58k [00:01<00:35, 231KB/s]\r  4%|▍         | 324/8.58k [00:01<00:35, 235KB/s]\r  5%|▍         | 427/8.58k [00:01<00:22, 367KB/s]\r  7%|▋         | 596/8.58k [00:01<00:13, 588KB/s]\r 10%|▉         | 818/8.58k [00:01<00:09, 844KB/s]\r 17%|█▋        | 1.44k/8.58k [00:02<00:03, 1.81kKB/s]\r 24%|██▍       | 2.10k/8.58k [00:02<00:02, 2.54kKB/s]\r 43%|████▎     | 3.66k/8.58k [00:02<00:01, 4.81kKB/s]\r 57%|█████▋    | 4.87k/8.58k [00:02<00:00, 5.72kKB/s]\r 75%|███████▍  | 6.43k/8.58k [00:02<00:00, 7.03kKB/s]\r 89%|████████▉ | 7.66k/8.58k [00:02<00:00, 7.31kKB/s]\r100%|██████████| 8.58k/8.58k [00:02<00:00, 2.95kKB/s]\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["\r  0%|          | 0.00/8.58k [00:00<?, ?KB/s]\r  0%|          | 13.0/8.58k [00:00<01:19, 108KB/s]\r  0%|          | 41.0/8.58k [00:00<00:42, 199KB/s]\r  1%|          | 68.0/8.58k [00:00<00:52, 163KB/s]\r  1%|          | 98.0/8.58k [00:00<00:48, 175KB/s]\r  2%|▏         | 140/8.58k [00:00<00:40, 210KB/s] \r  2%|▏         | 173/8.58k [00:00<00:39, 211KB/s]\r  2%|▏         | 210/8.58k [00:01<00:37, 221KB/s]\r  3%|▎         | 253/8.58k [00:01<00:34, 239KB/s]\r  3%|▎         | 286/8.58k [00:01<00:35, 231KB/s]\r  4%|▍         | 324/8.58k [00:01<00:35, 235KB/s]\r  5%|▍         | 427/8.58k [00:01<00:22, 367KB/s]\r  7%|▋         | 596/8.58k [00:01<00:13, 588KB/s]\r 10%|▉         | 818/8.58k [00:01<00:09, 844KB/s]\r 17%|█▋        | 1.44k/8.58k [00:02<00:03, 1.81kKB/s]\r 24%|██▍       | 2.10k/8.58k [00:02<00:02, 2.54kKB/s]\r 43%|████▎     | 3.66k/8.58k [00:02<00:01, 4.81kKB/s]\r 57%|█████▋    | 4.87k/8.58k [00:02<00:00, 5.72kKB/s]\r 75%|███████▍  | 6.43k/8.58k [00:02<00:00, 7.03kKB/s]\r 89%|████████▉ | 7.66k/8.58k [00:02<00:00, 7.31kKB/s]\r100%|██████████| 8.58k/8.58k [00:02<00:00, 2.95kKB/s]\n"]},"transient":null},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>int00</th>\n      <th>int01</th>\n      <th>int02</th>\n      <th>int03</th>\n      <th>int04</th>\n      <th>int05</th>\n      <th>int06</th>\n      <th>int07</th>\n      <th>int08</th>\n      <th>...</th>\n      <th>cat16</th>\n      <th>cat17</th>\n      <th>cat18</th>\n      <th>cat19</th>\n      <th>cat20</th>\n      <th>cat21</th>\n      <th>cat22</th>\n      <th>cat23</th>\n      <th>cat24</th>\n      <th>cat25</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n      <td>0</td>\n      <td>1382</td>\n      <td>4</td>\n      <td>15</td>\n      <td>2</td>\n      <td>181</td>\n      <td>...</td>\n      <td>e5ba7672</td>\n      <td>f54016b9</td>\n      <td>21ddcdc9</td>\n      <td>b1252a9d</td>\n      <td>07b5194c</td>\n      <td>None</td>\n      <td>3a171ecb</td>\n      <td>c5c50484</td>\n      <td>e8b83407</td>\n      <td>9727dd16</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>44</td>\n      <td>1</td>\n      <td>102</td>\n      <td>8</td>\n      <td>2</td>\n      <td>2</td>\n      <td>4</td>\n      <td>...</td>\n      <td>07c540c4</td>\n      <td>b04e4670</td>\n      <td>21ddcdc9</td>\n      <td>5840adea</td>\n      <td>60f6221e</td>\n      <td>None</td>\n      <td>3a171ecb</td>\n      <td>43f13e8b</td>\n      <td>e8b83407</td>\n      <td>731c3655</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 40 columns</p>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>int00</th>\n      <th>int01</th>\n      <th>int02</th>\n      <th>int03</th>\n      <th>int04</th>\n      <th>int05</th>\n      <th>int06</th>\n      <th>int07</th>\n      <th>int08</th>\n      <th>...</th>\n      <th>cat16</th>\n      <th>cat17</th>\n      <th>cat18</th>\n      <th>cat19</th>\n      <th>cat20</th>\n      <th>cat21</th>\n      <th>cat22</th>\n      <th>cat23</th>\n      <th>cat24</th>\n      <th>cat25</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n      <td>0</td>\n      <td>1382</td>\n      <td>4</td>\n      <td>15</td>\n      <td>2</td>\n      <td>181</td>\n      <td>...</td>\n      <td>e5ba7672</td>\n      <td>f54016b9</td>\n      <td>21ddcdc9</td>\n      <td>b1252a9d</td>\n      <td>07b5194c</td>\n      <td>None</td>\n      <td>3a171ecb</td>\n      <td>c5c50484</td>\n      <td>e8b83407</td>\n      <td>9727dd16</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>44</td>\n      <td>1</td>\n      <td>102</td>\n      <td>8</td>\n      <td>2</td>\n      <td>2</td>\n      <td>4</td>\n      <td>...</td>\n      <td>07c540c4</td>\n      <td>b04e4670</td>\n      <td>21ddcdc9</td>\n      <td>5840adea</td>\n      <td>60f6221e</td>\n      <td>None</td>\n      <td>3a171ecb</td>\n      <td>43f13e8b</td>\n      <td>e8b83407</td>\n      <td>731c3655</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 40 columns</p>\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["raw_train, raw_test = spark_random_split(raw_data, ratio=0.8, seed=42)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"737bfe77-fb10-43a0-8d29-3217ec38e2df"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["columns = [c for c in raw_data.columns if c != 'label']\nfeature_processor = FeatureHasher(inputCols=columns, outputCol='features')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cefa1b64-419d-497a-baf6-d396f33faf7a"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["train = feature_processor.transform(raw_train)\ntest = feature_processor.transform(raw_test)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ae07c5ea-a9ec-41c5-bc94-08107f66194e"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["lgbm = LightGBMClassifier(\n    labelCol=\"label\",\n    featuresCol=\"features\",\n    objective=\"binary\",\n    isUnbalance=True,\n    boostingType=\"gbdt\",\n    boostFromAverage=True,\n    baggingSeed=42,\n    numLeaves=NUM_LEAVES,\n    numIterations=NUM_ITERATIONS,\n    learningRate=LEARNING_RATE,\n    featureFraction=FEATURE_FRACTION,\n    earlyStoppingRound=EARLY_STOPPING_ROUND\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b7db875a-9373-4dfb-98e7-3f03614ba7c6"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["model = lgbm.fit(train)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"664585f8-1ba6-4bd4-8570-5e5a40d6655e"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["predictions = model.transform(test)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2b35045b-6c88-48e3-ae41-bfcdefce0fd3"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["evaluator = (\n    ComputeModelStatistics()\n    .setScoredLabelsCol(\"prediction\")\n    .setLabelCol(\"label\")\n    .setEvaluationMetric(\"AUC\")\n)\n\nresult = evaluator.transform(predictions)\nauc = result.select(\"AUC\").collect()[0][0]\nresult.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"89f00c08-602f-451e-a68b-5983ea6faafe"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---------------+------------------+\n|evaluation_type|               AUC|\n+---------------+------------------+\n| Classification|0.6213613998849201|\n+---------------+------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---------------+------------------+\n|evaluation_type|               AUC|\n+---------------+------------------+\n| Classification|0.6213613998849201|\n+---------------+------------------+\n\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Record results with papermill for tests\nsb.glue(\"auc\", auc)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9d8d2e61-45a6-4eed-bcdc-94be2373c112"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# save model\npipeline = PipelineModel(stages=[feature_processor, model])\npipeline.write().overwrite().save(MODEL_NAME)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a74b4c75-c57c-4c20-bc77-10807a8747dc"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mPy4JJavaError\u001B[0m                             Traceback (most recent call last)\n\u001B[0;32m<command-1623646647458095>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# save model\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0mpipeline\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mPipelineModel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstages\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mfeature_processor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mpipeline\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwrite\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moverwrite\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mMODEL_NAME\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\n\u001B[0;32m/databricks/spark/python/pyspark/ml/util.py\u001B[0m in \u001B[0;36msave\u001B[0;34m(self, path)\u001B[0m\n\u001B[1;32m    306\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    307\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mTypeError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"path should be a string, got type %s\"\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0mtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 308\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jwrite\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    309\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    310\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0moverwrite\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1302\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1303\u001B[0m         \u001B[0manswer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgateway_client\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msend_command\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcommand\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1304\u001B[0;31m         return_value = get_return_value(\n\u001B[0m\u001B[1;32m   1305\u001B[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001B[1;32m   1306\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/pyspark/sql/utils.py\u001B[0m in \u001B[0;36mdeco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    115\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mdeco\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    116\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 117\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    118\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mpy4j\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprotocol\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mPy4JJavaError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    119\u001B[0m             \u001B[0mconverted\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconvert_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjava_exception\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\u001B[0m in \u001B[0;36mget_return_value\u001B[0;34m(answer, gateway_client, target_id, name)\u001B[0m\n\u001B[1;32m    324\u001B[0m             \u001B[0mvalue\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mOUTPUT_CONVERTER\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtype\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0manswer\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgateway_client\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    325\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0manswer\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mREFERENCE_TYPE\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 326\u001B[0;31m                 raise Py4JJavaError(\n\u001B[0m\u001B[1;32m    327\u001B[0m                     \u001B[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    328\u001B[0m                     format(target_id, \".\", name), value)\n\n\u001B[0;31mPy4JJavaError\u001B[0m: An error occurred while calling o740.save.\n: java.lang.NoClassDefFoundError: org/json4s/JsonListAssoc$\n\tat org.apache.spark.ml.ComplexParamsWriter$.getMetadataToSave(ComplexParamsSerializer.scala:126)\n\tat org.apache.spark.ml.ComplexParamsWriter$.saveMetadata(ComplexParamsSerializer.scala:97)\n\tat org.apache.spark.ml.ComplexParamsWriter.saveImpl(ComplexParamsSerializer.scala:40)\n\tat org.apache.spark.ml.util.MLWriter.save(ReadWrite.scala:168)\n\tat org.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$saveImpl$5(Pipeline.scala:257)\n\tat org.apache.spark.ml.MLEvents.withSaveInstanceEvent(events.scala:175)\n\tat org.apache.spark.ml.MLEvents.withSaveInstanceEvent$(events.scala:170)\n\tat org.apache.spark.ml.util.Instrumentation.withSaveInstanceEvent(Instrumentation.scala:43)\n\tat org.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$saveImpl$4(Pipeline.scala:257)\n\tat org.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$saveImpl$4$adapted(Pipeline.scala:254)\n\tat scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\n\tat scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\n\tat org.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$saveImpl$1(Pipeline.scala:254)\n\tat org.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$saveImpl$1$adapted(Pipeline.scala:247)\n\tat org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:284)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:284)\n\tat org.apache.spark.ml.Pipeline$SharedReadWrite$.saveImpl(Pipeline.scala:247)\n\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.saveImpl(Pipeline.scala:346)\n\tat org.apache.spark.ml.util.MLWriter.save(ReadWrite.scala:168)\n\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.super$save(Pipeline.scala:344)\n\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$4(Pipeline.scala:344)\n\tat org.apache.spark.ml.MLEvents.withSaveInstanceEvent(events.scala:175)\n\tat org.apache.spark.ml.MLEvents.withSaveInstanceEvent$(events.scala:170)\n\tat org.apache.spark.ml.util.Instrumentation.withSaveInstanceEvent(Instrumentation.scala:43)\n\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$3(Pipeline.scala:344)\n\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$3$adapted(Pipeline.scala:344)\n\tat org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:284)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:284)\n\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.save(Pipeline.scala:344)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.ClassNotFoundException: org.json4s.JsonListAssoc$\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:382)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:419)\n\tat com.databricks.backend.daemon.driver.ClassLoaders$LibraryClassLoader.loadClass(ClassLoaders.scala:151)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:352)\n\t... 43 more\n","errorSummary":"java.lang.NoClassDefFoundError: org/json4s/JsonListAssoc$","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mPy4JJavaError\u001B[0m                             Traceback (most recent call last)\n\u001B[0;32m<command-1623646647458095>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# save model\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0mpipeline\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mPipelineModel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstages\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mfeature_processor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mpipeline\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwrite\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moverwrite\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mMODEL_NAME\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\n\u001B[0;32m/databricks/spark/python/pyspark/ml/util.py\u001B[0m in \u001B[0;36msave\u001B[0;34m(self, path)\u001B[0m\n\u001B[1;32m    306\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    307\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mTypeError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"path should be a string, got type %s\"\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0mtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 308\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jwrite\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    309\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    310\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0moverwrite\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1302\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1303\u001B[0m         \u001B[0manswer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgateway_client\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msend_command\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcommand\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1304\u001B[0;31m         return_value = get_return_value(\n\u001B[0m\u001B[1;32m   1305\u001B[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001B[1;32m   1306\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/pyspark/sql/utils.py\u001B[0m in \u001B[0;36mdeco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    115\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mdeco\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    116\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 117\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    118\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mpy4j\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprotocol\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mPy4JJavaError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    119\u001B[0m             \u001B[0mconverted\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconvert_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjava_exception\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\u001B[0m in \u001B[0;36mget_return_value\u001B[0;34m(answer, gateway_client, target_id, name)\u001B[0m\n\u001B[1;32m    324\u001B[0m             \u001B[0mvalue\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mOUTPUT_CONVERTER\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtype\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0manswer\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgateway_client\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    325\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0manswer\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mREFERENCE_TYPE\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 326\u001B[0;31m                 raise Py4JJavaError(\n\u001B[0m\u001B[1;32m    327\u001B[0m                     \u001B[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    328\u001B[0m                     format(target_id, \".\", name), value)\n\n\u001B[0;31mPy4JJavaError\u001B[0m: An error occurred while calling o740.save.\n: java.lang.NoClassDefFoundError: org/json4s/JsonListAssoc$\n\tat org.apache.spark.ml.ComplexParamsWriter$.getMetadataToSave(ComplexParamsSerializer.scala:126)\n\tat org.apache.spark.ml.ComplexParamsWriter$.saveMetadata(ComplexParamsSerializer.scala:97)\n\tat org.apache.spark.ml.ComplexParamsWriter.saveImpl(ComplexParamsSerializer.scala:40)\n\tat org.apache.spark.ml.util.MLWriter.save(ReadWrite.scala:168)\n\tat org.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$saveImpl$5(Pipeline.scala:257)\n\tat org.apache.spark.ml.MLEvents.withSaveInstanceEvent(events.scala:175)\n\tat org.apache.spark.ml.MLEvents.withSaveInstanceEvent$(events.scala:170)\n\tat org.apache.spark.ml.util.Instrumentation.withSaveInstanceEvent(Instrumentation.scala:43)\n\tat org.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$saveImpl$4(Pipeline.scala:257)\n\tat org.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$saveImpl$4$adapted(Pipeline.scala:254)\n\tat scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\n\tat scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\n\tat org.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$saveImpl$1(Pipeline.scala:254)\n\tat org.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$saveImpl$1$adapted(Pipeline.scala:247)\n\tat org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:284)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:284)\n\tat org.apache.spark.ml.Pipeline$SharedReadWrite$.saveImpl(Pipeline.scala:247)\n\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.saveImpl(Pipeline.scala:346)\n\tat org.apache.spark.ml.util.MLWriter.save(ReadWrite.scala:168)\n\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.super$save(Pipeline.scala:344)\n\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$4(Pipeline.scala:344)\n\tat org.apache.spark.ml.MLEvents.withSaveInstanceEvent(events.scala:175)\n\tat org.apache.spark.ml.MLEvents.withSaveInstanceEvent$(events.scala:170)\n\tat org.apache.spark.ml.util.Instrumentation.withSaveInstanceEvent(Instrumentation.scala:43)\n\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$3(Pipeline.scala:344)\n\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$3$adapted(Pipeline.scala:344)\n\tat org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:284)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:284)\n\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.save(Pipeline.scala:344)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.ClassNotFoundException: org.json4s.JsonListAssoc$\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:382)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:419)\n\tat com.databricks.backend.daemon.driver.ClassLoaders$LibraryClassLoader.loadClass(ClassLoaders.scala:151)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:352)\n\t... 43 more\n"]},"transient":null}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"mec-17.2.3-lightgbm_williford","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":1335230443985961}},"nbformat":4,"nbformat_minor":0}
