{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YhAEgCTZzjZe"
   },
   "source": [
    "This colab notebook is based on : https://developers.google.com/machine-learning/guides/text-classification.\n",
    "\n",
    "Note this is the Option A implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WFjkX2W616GR"
   },
   "source": [
    "Read In Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3003,
     "status": "ok",
     "timestamp": 1643693309665,
     "user": {
      "displayName": "Dave Williford",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg1oB0_dFMci-8J9hCWjfFgiRe6DHGeTdAG7OWf2A=s64",
      "userId": "07870752706515771222"
     },
     "user_tz": 480
    },
    "id": "bNEWZPvyyX2O",
    "outputId": "c9edfa65-e092-4828-8736-330e3d1a20d1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "# the base Google Drive directory\n",
    "#root_dir = \"/content/drive/My Drive/\"\n",
    "\n",
    "# Should probably organize by project\n",
    "#project_folder = \"Colab Notebooks/My Project Folder/\"\n",
    "\n",
    "#base_data_location = root_dir + 'Colab Notebooks/data'\n",
    "#devotional_corpus = base_data_location + '/corpus_mod.json'\n",
    "\n",
    "\n",
    "base_data_location = 'C:/Users/Dave/git_repos/mec-mini-projects/mec-14-8-capstone-model/data'\n",
    "base_model_location = 'C:/Users/Dave/git_repos/mec-mini-projects/mec-14-8-capstone-model/models'\n",
    "devotional_corpus = base_data_location + '/corpus_mod.json'\n",
    "\n",
    "\n",
    "\n",
    "#load devotionals\n",
    "df = pd.read_json(devotional_corpus)\n",
    "\n",
    "# Get devotional ids for each collection and use as a label for supervised training\n",
    "#collections = {\"782\" : \"love\", \"924\" : \"joy\", \"290\" : \"peace\", \"906\" : \"hope\", \"809\" : \"depression\"}\n",
    "# Will also encode here\n",
    "collections = {\"782\" : 0, \"924\" : 1, \"290\" : 2, \"906\" : 3, \"809\" : 4}\n",
    "#collections = {\"1\" : \"toy\"}\n",
    "devo_labels = {}\n",
    "for collection in collections.keys():\n",
    "    input_file = open(base_data_location + '/collections/collection_' + str(collection) + '.json')\n",
    "    collection_data = json.load(input_file)\n",
    "    page = {}\n",
    "    for page in collection_data.values():\n",
    "        for reading_plan in page['collections'][0]['items']:\n",
    "            reading_plan_id = reading_plan['id']\n",
    "            #create array with reading_plan id and collection id\n",
    "            devo_labels[reading_plan_id] = collections[collection]\n",
    "    input_file.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 591,
     "status": "ok",
     "timestamp": 1643693310493,
     "user": {
      "displayName": "Dave Williford",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg1oB0_dFMci-8J9hCWjfFgiRe6DHGeTdAG7OWf2A=s64",
      "userId": "07870752706515771222"
     },
     "user_tz": 480
    },
    "id": "GWfmmTFSDibJ",
    "outputId": "cd57e964-4dcb-437e-e8b4-354f1bd9d302"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dave\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Dave\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Dave\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  import nltk\n",
    "  nltk.download('stopwords')\n",
    "  nltk.download('punkt')\n",
    "  nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1643693314515,
     "user": {
      "displayName": "Dave Williford",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg1oB0_dFMci-8J9hCWjfFgiRe6DHGeTdAG7OWf2A=s64",
      "userId": "07870752706515771222"
     },
     "user_tz": 480
    },
    "id": "rcQV64Hw4D20"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "def clean(text):\n",
    "    wn = nltk.WordNetLemmatizer()\n",
    "    stopword = nltk.corpus.stopwords.words('english')\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    lower = [word.lower() for word in tokens]\n",
    "    no_stopwords = [word for word in lower if word not in stopword]\n",
    "    no_alpha = [word for word in no_stopwords if word.isalpha()]\n",
    "    lemm_text = [wn.lemmatize(word) for word in no_alpha]\n",
    "    clean_text = lemm_text\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 246,
     "status": "ok",
     "timestamp": 1643693318212,
     "user": {
      "displayName": "Dave Williford",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg1oB0_dFMci-8J9hCWjfFgiRe6DHGeTdAG7OWf2A=s64",
      "userId": "07870752706515771222"
     },
     "user_tz": 480
    },
    "id": "l7rlfKm1FWBW",
    "outputId": "7752db78-2da7-4451-af51-43f5d1afc33e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                source_id      source          type  day  \\\n",
      "YV_RP_29045_1      29045  YouVersion  reading plan    1   \n",
      "YV_RP_29045_2      29045  YouVersion  reading plan    2   \n",
      "YV_RP_29045_3      29045  YouVersion  reading plan    3   \n",
      "YV_RP_28889_1      28889  YouVersion  reading plan    1   \n",
      "YV_RP_28889_2      28889  YouVersion  reading plan    2   \n",
      "...                  ...         ...           ...  ...   \n",
      "YV_RP_28716_1      28716  YouVersion  reading plan    1   \n",
      "YV_RP_28716_2      28716  YouVersion  reading plan    2   \n",
      "YV_RP_28716_3      28716  YouVersion  reading plan    3   \n",
      "YV_RP_28716_4      28716  YouVersion  reading plan    4   \n",
      "YV_RP_28716_5      28716  YouVersion  reading plan    5   \n",
      "\n",
      "                                                            text  \\\n",
      "YV_RP_29045_1  [IMAGE CONTENT] \\n\\nTHE GIFT OF JESUS \\n\\n  \\n...   \n",
      "YV_RP_29045_2  [IMAGE CONTENT] \\n\\nTHE GIFT OF SALVATION \\n\\n...   \n",
      "YV_RP_29045_3  SHARE JESUS, THE PERFECT GIFT \\n\\n  \\n\\n\\nChri...   \n",
      "YV_RP_28889_1  Being There for One Another \\n\\nWhat is the ev...   \n",
      "YV_RP_28889_2  Words That Bring Healing \\n\\nDo your words bri...   \n",
      "...                                                          ...   \n",
      "YV_RP_28716_1  #  BELOVED \\n\\nBeloved. The word itself hides ...   \n",
      "YV_RP_28716_2  #  NEEDY \\n\\nEach of us can recall being calle...   \n",
      "YV_RP_28716_3  #  GOD'S LIVING STATUE \\n\\nWhat does it mean t...   \n",
      "YV_RP_28716_4  #  YOU ARE A NAME GIVER \\n\\nEvery expectant or...   \n",
      "YV_RP_28716_5  #  THE NAME ABOVE EVERY OTHER: JESUS \\n\\nEven ...   \n",
      "\n",
      "                                                      references  \n",
      "YV_RP_29045_1  [JHN.3.16+JHN.3.17, LUK.2.11, ISA.7.14, COL.1....  \n",
      "YV_RP_29045_2  [EPH.2.8+EPH.2.9, 2CO.5.21, EPH.1.7, ROM.6.6, ...  \n",
      "YV_RP_29045_3                     [JHN.14.6, JHN.11.25, ACT.1.8]  \n",
      "YV_RP_28889_1                                         [JAS.2.14]  \n",
      "YV_RP_28889_2                                        [PRO.12.18]  \n",
      "...                                                          ...  \n",
      "YV_RP_28716_1  [GEN.1.28, GEN.1.31, PSA.116.7, LUK.10.30+LUK....  \n",
      "YV_RP_28716_2                                  [GEN.5.1+GEN.5.2]  \n",
      "YV_RP_28716_3  [GEN.1.26, EXO.20.4+EXO.20.5+EXO.20.6, DEU.5.8...  \n",
      "YV_RP_28716_4  [GEN.1.28, GEN.14.18+GEN.14.19+GEN.14.20, PSA....  \n",
      "YV_RP_28716_5  [PSA.110.1, ISA.53, MRK.10.45, HEB.2.14+HEB.2.15]  \n",
      "\n",
      "[7574 rows x 6 columns]>\n",
      "source_id                                                 29045\n",
      "source                                               YouVersion\n",
      "type                                               reading plan\n",
      "day                                                           1\n",
      "text          [IMAGE CONTENT] \\n\\nTHE GIFT OF JESUS \\n\\n  \\n...\n",
      "references    [JHN.3.16+JHN.3.17, LUK.2.11, ISA.7.14, COL.1....\n",
      "Name: YV_RP_29045_1, dtype: object\n",
      "source_id                                                 28850\n",
      "source                                               YouVersion\n",
      "type                                               reading plan\n",
      "day                                                           4\n",
      "text          Full of Joy \\n\\nWhat’s the secret to full joy?...\n",
      "references                                          [JHN.16.24]\n",
      "Name: YV_RP_28850_4, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.head)\n",
    "#print(df.iloc[0:2,])\n",
    "print(df.iloc[0])\n",
    "print(df.iloc[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34312,
     "status": "ok",
     "timestamp": 1643693354840,
     "user": {
      "displayName": "Dave Williford",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg1oB0_dFMci-8J9hCWjfFgiRe6DHGeTdAG7OWf2A=s64",
      "userId": "07870752706515771222"
     },
     "user_tz": 480
    },
    "id": "XQGc5Z3t2nNF",
    "outputId": "305e75c2-c2da-4dd3-89e8-bf4b908d90ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                source_id      source          type  day  \\\n",
      "YV_RP_29045_1      29045  YouVersion  reading plan    1   \n",
      "YV_RP_29045_2      29045  YouVersion  reading plan    2   \n",
      "YV_RP_29045_3      29045  YouVersion  reading plan    3   \n",
      "YV_RP_28889_1      28889  YouVersion  reading plan    1   \n",
      "YV_RP_28889_2      28889  YouVersion  reading plan    2   \n",
      "...                  ...         ...           ...  ...   \n",
      "YV_RP_28716_1      28716  YouVersion  reading plan    1   \n",
      "YV_RP_28716_2      28716  YouVersion  reading plan    2   \n",
      "YV_RP_28716_3      28716  YouVersion  reading plan    3   \n",
      "YV_RP_28716_4      28716  YouVersion  reading plan    4   \n",
      "YV_RP_28716_5      28716  YouVersion  reading plan    5   \n",
      "\n",
      "                                                            text  \\\n",
      "YV_RP_29045_1  [IMAGE CONTENT] \\n\\nTHE GIFT OF JESUS \\n\\n  \\n...   \n",
      "YV_RP_29045_2  [IMAGE CONTENT] \\n\\nTHE GIFT OF SALVATION \\n\\n...   \n",
      "YV_RP_29045_3  SHARE JESUS, THE PERFECT GIFT \\n\\n  \\n\\n\\nChri...   \n",
      "YV_RP_28889_1  Being There for One Another \\n\\nWhat is the ev...   \n",
      "YV_RP_28889_2  Words That Bring Healing \\n\\nDo your words bri...   \n",
      "...                                                          ...   \n",
      "YV_RP_28716_1  #  BELOVED \\n\\nBeloved. The word itself hides ...   \n",
      "YV_RP_28716_2  #  NEEDY \\n\\nEach of us can recall being calle...   \n",
      "YV_RP_28716_3  #  GOD'S LIVING STATUE \\n\\nWhat does it mean t...   \n",
      "YV_RP_28716_4  #  YOU ARE A NAME GIVER \\n\\nEvery expectant or...   \n",
      "YV_RP_28716_5  #  THE NAME ABOVE EVERY OTHER: JESUS \\n\\nEven ...   \n",
      "\n",
      "                                                      references  \n",
      "YV_RP_29045_1  [JHN.3.16+JHN.3.17, LUK.2.11, ISA.7.14, COL.1....  \n",
      "YV_RP_29045_2  [EPH.2.8+EPH.2.9, 2CO.5.21, EPH.1.7, ROM.6.6, ...  \n",
      "YV_RP_29045_3                     [JHN.14.6, JHN.11.25, ACT.1.8]  \n",
      "YV_RP_28889_1                                         [JAS.2.14]  \n",
      "YV_RP_28889_2                                        [PRO.12.18]  \n",
      "...                                                          ...  \n",
      "YV_RP_28716_1  [GEN.1.28, GEN.1.31, PSA.116.7, LUK.10.30+LUK....  \n",
      "YV_RP_28716_2                                  [GEN.5.1+GEN.5.2]  \n",
      "YV_RP_28716_3  [GEN.1.26, EXO.20.4+EXO.20.5+EXO.20.6, DEU.5.8...  \n",
      "YV_RP_28716_4  [GEN.1.28, GEN.14.18+GEN.14.19+GEN.14.20, PSA....  \n",
      "YV_RP_28716_5  [PSA.110.1, ISA.53, MRK.10.45, HEB.2.14+HEB.2.15]  \n",
      "\n",
      "[7574 rows x 6 columns]>\n",
      "               source_id      source          type  day  \\\n",
      "YV_RP_29045_1      29045  YouVersion  reading plan    1   \n",
      "\n",
      "                                                            text  \\\n",
      "YV_RP_29045_1  [IMAGE CONTENT] \\n\\nTHE GIFT OF JESUS \\n\\n  \\n...   \n",
      "\n",
      "                                                      references  \n",
      "YV_RP_29045_1  [JHN.3.16+JHN.3.17, LUK.2.11, ISA.7.14, COL.1....  \n",
      "<bound method NDFrame.head of        Collection\n",
      "29045           0\n",
      "28889           0\n",
      "28850           1\n",
      "28924           3\n",
      "28967           0\n",
      "...           ...\n",
      "25185           4\n",
      "16828           4\n",
      "12822           4\n",
      "17577           4\n",
      "28716           4\n",
      "\n",
      "[940 rows x 1 columns]>\n",
      "<bound method NDFrame.head of                source_id      source          type  day  \\\n",
      "YV_RP_29045_1      29045  YouVersion  reading plan    1   \n",
      "YV_RP_29045_2      29045  YouVersion  reading plan    2   \n",
      "YV_RP_29045_3      29045  YouVersion  reading plan    3   \n",
      "YV_RP_28889_1      28889  YouVersion  reading plan    1   \n",
      "YV_RP_28889_2      28889  YouVersion  reading plan    2   \n",
      "...                  ...         ...           ...  ...   \n",
      "YV_RP_28716_1      28716  YouVersion  reading plan    1   \n",
      "YV_RP_28716_2      28716  YouVersion  reading plan    2   \n",
      "YV_RP_28716_3      28716  YouVersion  reading plan    3   \n",
      "YV_RP_28716_4      28716  YouVersion  reading plan    4   \n",
      "YV_RP_28716_5      28716  YouVersion  reading plan    5   \n",
      "\n",
      "                                                            text  \\\n",
      "YV_RP_29045_1  [IMAGE CONTENT] \\n\\nTHE GIFT OF JESUS \\n\\n  \\n...   \n",
      "YV_RP_29045_2  [IMAGE CONTENT] \\n\\nTHE GIFT OF SALVATION \\n\\n...   \n",
      "YV_RP_29045_3  SHARE JESUS, THE PERFECT GIFT \\n\\n  \\n\\n\\nChri...   \n",
      "YV_RP_28889_1  Being There for One Another \\n\\nWhat is the ev...   \n",
      "YV_RP_28889_2  Words That Bring Healing \\n\\nDo your words bri...   \n",
      "...                                                          ...   \n",
      "YV_RP_28716_1  #  BELOVED \\n\\nBeloved. The word itself hides ...   \n",
      "YV_RP_28716_2  #  NEEDY \\n\\nEach of us can recall being calle...   \n",
      "YV_RP_28716_3  #  GOD'S LIVING STATUE \\n\\nWhat does it mean t...   \n",
      "YV_RP_28716_4  #  YOU ARE A NAME GIVER \\n\\nEvery expectant or...   \n",
      "YV_RP_28716_5  #  THE NAME ABOVE EVERY OTHER: JESUS \\n\\nEven ...   \n",
      "\n",
      "                                                      references  Collection  \n",
      "YV_RP_29045_1  [JHN.3.16+JHN.3.17, LUK.2.11, ISA.7.14, COL.1....           0  \n",
      "YV_RP_29045_2  [EPH.2.8+EPH.2.9, 2CO.5.21, EPH.1.7, ROM.6.6, ...           0  \n",
      "YV_RP_29045_3                     [JHN.14.6, JHN.11.25, ACT.1.8]           0  \n",
      "YV_RP_28889_1                                         [JAS.2.14]           0  \n",
      "YV_RP_28889_2                                        [PRO.12.18]           0  \n",
      "...                                                          ...         ...  \n",
      "YV_RP_28716_1  [GEN.1.28, GEN.1.31, PSA.116.7, LUK.10.30+LUK....           4  \n",
      "YV_RP_28716_2                                  [GEN.5.1+GEN.5.2]           4  \n",
      "YV_RP_28716_3  [GEN.1.26, EXO.20.4+EXO.20.5+EXO.20.6, DEU.5.8...           4  \n",
      "YV_RP_28716_4  [GEN.1.28, GEN.14.18+GEN.14.19+GEN.14.20, PSA....           4  \n",
      "YV_RP_28716_5  [PSA.110.1, ISA.53, MRK.10.45, HEB.2.14+HEB.2.15]           4  \n",
      "\n",
      "[7574 rows x 7 columns]>\n",
      "source_id                                                 29045\n",
      "source                                               YouVersion\n",
      "type                                               reading plan\n",
      "day                                                           1\n",
      "text          [IMAGE CONTENT] \\n\\nTHE GIFT OF JESUS \\n\\n  \\n...\n",
      "references    [JHN.3.16+JHN.3.17, LUK.2.11, ISA.7.14, COL.1....\n",
      "Collection                                                    0\n",
      "Name: YV_RP_29045_1, dtype: object\n",
      "source_id                                                 28850\n",
      "source                                               YouVersion\n",
      "type                                               reading plan\n",
      "day                                                           4\n",
      "text          Full of Joy \\n\\nWhat’s the secret to full joy?...\n",
      "references                                          [JHN.16.24]\n",
      "Collection                                                    1\n",
      "Name: YV_RP_28850_4, dtype: object\n",
      "<bound method NDFrame.head of                source_id      source          type  day  \\\n",
      "YV_RP_29045_1      29045  YouVersion  reading plan    1   \n",
      "YV_RP_29045_2      29045  YouVersion  reading plan    2   \n",
      "YV_RP_29045_3      29045  YouVersion  reading plan    3   \n",
      "YV_RP_28889_1      28889  YouVersion  reading plan    1   \n",
      "YV_RP_28889_2      28889  YouVersion  reading plan    2   \n",
      "...                  ...         ...           ...  ...   \n",
      "YV_RP_28716_1      28716  YouVersion  reading plan    1   \n",
      "YV_RP_28716_2      28716  YouVersion  reading plan    2   \n",
      "YV_RP_28716_3      28716  YouVersion  reading plan    3   \n",
      "YV_RP_28716_4      28716  YouVersion  reading plan    4   \n",
      "YV_RP_28716_5      28716  YouVersion  reading plan    5   \n",
      "\n",
      "                                                            text  \\\n",
      "YV_RP_29045_1  [IMAGE CONTENT] \\n\\nTHE GIFT OF JESUS \\n\\n  \\n...   \n",
      "YV_RP_29045_2  [IMAGE CONTENT] \\n\\nTHE GIFT OF SALVATION \\n\\n...   \n",
      "YV_RP_29045_3  SHARE JESUS, THE PERFECT GIFT \\n\\n  \\n\\n\\nChri...   \n",
      "YV_RP_28889_1  Being There for One Another \\n\\nWhat is the ev...   \n",
      "YV_RP_28889_2  Words That Bring Healing \\n\\nDo your words bri...   \n",
      "...                                                          ...   \n",
      "YV_RP_28716_1  #  BELOVED \\n\\nBeloved. The word itself hides ...   \n",
      "YV_RP_28716_2  #  NEEDY \\n\\nEach of us can recall being calle...   \n",
      "YV_RP_28716_3  #  GOD'S LIVING STATUE \\n\\nWhat does it mean t...   \n",
      "YV_RP_28716_4  #  YOU ARE A NAME GIVER \\n\\nEvery expectant or...   \n",
      "YV_RP_28716_5  #  THE NAME ABOVE EVERY OTHER: JESUS \\n\\nEven ...   \n",
      "\n",
      "                                                      references  Collection  \\\n",
      "YV_RP_29045_1  [JHN.3.16+JHN.3.17, LUK.2.11, ISA.7.14, COL.1....           0   \n",
      "YV_RP_29045_2  [EPH.2.8+EPH.2.9, 2CO.5.21, EPH.1.7, ROM.6.6, ...           0   \n",
      "YV_RP_29045_3                     [JHN.14.6, JHN.11.25, ACT.1.8]           0   \n",
      "YV_RP_28889_1                                         [JAS.2.14]           0   \n",
      "YV_RP_28889_2                                        [PRO.12.18]           0   \n",
      "...                                                          ...         ...   \n",
      "YV_RP_28716_1  [GEN.1.28, GEN.1.31, PSA.116.7, LUK.10.30+LUK....           4   \n",
      "YV_RP_28716_2                                  [GEN.5.1+GEN.5.2]           4   \n",
      "YV_RP_28716_3  [GEN.1.26, EXO.20.4+EXO.20.5+EXO.20.6, DEU.5.8...           4   \n",
      "YV_RP_28716_4  [GEN.1.28, GEN.14.18+GEN.14.19+GEN.14.20, PSA....           4   \n",
      "YV_RP_28716_5  [PSA.110.1, ISA.53, MRK.10.45, HEB.2.14+HEB.2.15]           4   \n",
      "\n",
      "                                                      clean_text  \\\n",
      "YV_RP_29045_1  [image, content, gift, jesus, looking, perfect...   \n",
      "YV_RP_29045_2  [image, content, gift, salvation, love, gettin...   \n",
      "YV_RP_29045_3  [share, jesus, perfect, gift, christian, calle...   \n",
      "YV_RP_28889_1  [one, another, evidence, faith, meditate, jame...   \n",
      "YV_RP_28889_2  [word, bring, healing, word, bring, hurt, heal...   \n",
      "...                                                          ...   \n",
      "YV_RP_28716_1  [beloved, beloved, word, hide, within, definit...   \n",
      "YV_RP_28716_2  [needy, u, recall, called, name, want, embrace...   \n",
      "YV_RP_28716_3  [god, living, statue, mean, image, bearer, god...   \n",
      "YV_RP_28716_4  [name, giver, every, expectant, hopeful, paren...   \n",
      "YV_RP_28716_5  [name, every, jesus, even, though, name, power...   \n",
      "\n",
      "                                             clean_text_combined  \n",
      "YV_RP_29045_1  image content gift jesus looking perfect gift ...  \n",
      "YV_RP_29045_2  image content gift salvation love getting free...  \n",
      "YV_RP_29045_3  share jesus perfect gift christian called witn...  \n",
      "YV_RP_28889_1  one another evidence faith meditate james audi...  \n",
      "YV_RP_28889_2  word bring healing word bring hurt healing med...  \n",
      "...                                                          ...  \n",
      "YV_RP_28716_1  beloved beloved word hide within definition lo...  \n",
      "YV_RP_28716_2  needy u recall called name want embrace stupid...  \n",
      "YV_RP_28716_3  god living statue mean image bearer god phrase...  \n",
      "YV_RP_28716_4  name giver every expectant hopeful parent know...  \n",
      "YV_RP_28716_5  name every jesus even though name powerful one...  \n",
      "\n",
      "[7574 rows x 9 columns]>\n",
      "source_id                                                          29045\n",
      "source                                                        YouVersion\n",
      "type                                                        reading plan\n",
      "day                                                                    1\n",
      "text                   [IMAGE CONTENT] \\n\\nTHE GIFT OF JESUS \\n\\n  \\n...\n",
      "references             [JHN.3.16+JHN.3.17, LUK.2.11, ISA.7.14, COL.1....\n",
      "Collection                                                             0\n",
      "clean_text             [image, content, gift, jesus, looking, perfect...\n",
      "clean_text_combined    image content gift jesus looking perfect gift ...\n",
      "Name: YV_RP_29045_1, dtype: object\n",
      "source_id                                                          28850\n",
      "source                                                        YouVersion\n",
      "type                                                        reading plan\n",
      "day                                                                    4\n",
      "text                   Full of Joy \\n\\nWhat’s the secret to full joy?...\n",
      "references                                                   [JHN.16.24]\n",
      "Collection                                                             1\n",
      "clean_text             [full, joy, secret, full, joy, meditate, john,...\n",
      "clean_text_combined    full joy secret full joy meditate john audio a...\n",
      "Name: YV_RP_28850_4, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.head)\n",
    "print(df[0:1])\n",
    "\n",
    "# Create dataframe from label dictionary\n",
    "label_df = pd.DataFrame.from_dict(devo_labels, orient='index', columns=['Collection'])\n",
    "print(label_df.head)\n",
    "\n",
    "# Combine devotionals with collection labels\n",
    "combined_df = pd.merge(df, label_df, how='left', left_on=['source_id'], right_index=True)\n",
    "print(combined_df.head)\n",
    "print(combined_df.iloc[0])\n",
    "print(combined_df.iloc[10])\n",
    "\n",
    "combined_df['clean_text'] = combined_df.apply(lambda row : clean(row['text']), axis = 1)\n",
    "# Need a version with tokens recombined so they can be retokenized later...\n",
    "combined_df['clean_text_combined'] = combined_df.apply(lambda row : \" \".join(row['clean_text']), axis = 1)\n",
    "\n",
    "print(combined_df.head)\n",
    "print(combined_df.iloc[0])\n",
    "print(combined_df.iloc[10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1643693354841,
     "user": {
      "displayName": "Dave Williford",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg1oB0_dFMci-8J9hCWjfFgiRe6DHGeTdAG7OWf2A=s64",
      "userId": "07870752706515771222"
     },
     "user_tz": 480
    },
    "id": "KDwvUVEflU-Z"
   },
   "outputs": [],
   "source": [
    "#Create single arrays of cleaned text and labels for training/testing\n",
    "y = combined_df['Collection'].to_numpy()\n",
    "#X = combined_df['clean_text_combined'].to_numpy()\n",
    "X = combined_df['clean_text_combined'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 266,
     "status": "ok",
     "timestamp": 1643693357638,
     "user": {
      "displayName": "Dave Williford",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg1oB0_dFMci-8J9hCWjfFgiRe6DHGeTdAG7OWf2A=s64",
      "userId": "07870752706515771222"
     },
     "user_tz": 480
    },
    "id": "9EmB-ZeA4iey"
   },
   "outputs": [],
   "source": [
    "#Split training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v1ZOQ68AzBgS"
   },
   "source": [
    "Step 3: Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 235,
     "status": "ok",
     "timestamp": 1643693364335,
     "user": {
      "displayName": "Dave Williford",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg1oB0_dFMci-8J9hCWjfFgiRe6DHGeTdAG7OWf2A=s64",
      "userId": "07870752706515771222"
     },
     "user_tz": 480
    },
    "id": "-72_1MqkpLy8"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "# Vectorization parameters\n",
    "\n",
    "# Range (inclusive) of n-gram sizes for tokenizing text.\n",
    "NGRAM_RANGE = (1, 2)\n",
    "\n",
    "# Limit on the number of features. We use the top 20K features.\n",
    "TOP_K = 20000\n",
    "\n",
    "# Whether text should be split into word or character n-grams.\n",
    "# One of 'word', 'char'.\n",
    "TOKEN_MODE = 'word'\n",
    "\n",
    "# Minimum document/corpus frequency below which a token will be discarded.\n",
    "MIN_DOCUMENT_FREQUENCY = 2\n",
    "\n",
    "# Limit on the length of text sequences. Sequences longer than this\n",
    "# will be truncated.\n",
    "MAX_SEQUENCE_LENGTH = 500\n",
    "\n",
    "def ngram_vectorize(train_texts, train_labels, val_texts):\n",
    "    \"\"\"Vectorizes texts as ngram vectors.\n",
    "    1 text = 1 tf-idf vector the length of vocabulary of uni-grams + bi-grams.\n",
    "    # Arguments\n",
    "        train_texts: list, training text strings.\n",
    "        train_labels: np.ndarray, training labels.\n",
    "        val_texts: list, validation text strings.\n",
    "    # Returns\n",
    "        x_train, x_val: vectorized training and validation texts\n",
    "    \"\"\"\n",
    "    # Create keyword arguments to pass to the 'tf-idf' vectorizer.\n",
    "    kwargs = {\n",
    "            'ngram_range': NGRAM_RANGE,  # Use 1-grams + 2-grams.\n",
    "            'dtype': 'int32',\n",
    "            'strip_accents': 'unicode',\n",
    "            'decode_error': 'replace',\n",
    "            'analyzer': TOKEN_MODE,  # Split text into word tokens.\n",
    "            'min_df': MIN_DOCUMENT_FREQUENCY,\n",
    "    }\n",
    "    vectorizer = TfidfVectorizer(**kwargs)\n",
    "\n",
    "    # Learn vocabulary from training texts and vectorize training texts.\n",
    "    #x_train = vectorizer.fit_transform(train_texts)\n",
    "    x_train = vectorizer.fit_transform(train_texts).todense()\n",
    "    \n",
    "    # Vectorize validation texts.\n",
    "    #x_val = vectorizer.transform(val_texts)\n",
    "    x_val = vectorizer.transform(val_texts).todense()\n",
    "\n",
    "    # Select top 'k' of the vectorized features.\n",
    "    selector = SelectKBest(f_classif, k=min(TOP_K, x_train.shape[1]))\n",
    "    selector.fit(x_train, train_labels)\n",
    "    x_train = selector.transform(x_train)\n",
    "    x_val = selector.transform(x_val)\n",
    "\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_val = x_val.astype('float32')\n",
    "    return x_train, x_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8sG8OO26x7J"
   },
   "source": [
    "Construct a four-layer sepCNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 241,
     "status": "ok",
     "timestamp": 1643693368278,
     "user": {
      "displayName": "Dave Williford",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg1oB0_dFMci-8J9hCWjfFgiRe6DHGeTdAG7OWf2A=s64",
      "userId": "07870752706515771222"
     },
     "user_tz": 480
    },
    "id": "zT_8T8P_jM4Z"
   },
   "outputs": [],
   "source": [
    "def _get_last_layer_units_and_activation(num_classes):\n",
    "    \"\"\"Gets the # units and activation function for the last network layer.\n",
    "    # Arguments\n",
    "        num_classes: int, number of classes.\n",
    "    # Returns\n",
    "        units, activation values.\n",
    "    \"\"\"\n",
    "    if num_classes == 2:\n",
    "        activation = 'sigmoid'\n",
    "        units = 1\n",
    "    else:\n",
    "        activation = 'softmax'\n",
    "        units = num_classes\n",
    "    return units, activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 270,
     "status": "ok",
     "timestamp": 1643693369891,
     "user": {
      "displayName": "Dave Williford",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg1oB0_dFMci-8J9hCWjfFgiRe6DHGeTdAG7OWf2A=s64",
      "userId": "07870752706515771222"
     },
     "user_tz": 480
    },
    "id": "Jvpf4Dm-pkyW"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "def mlp_model(layers, units, dropout_rate, input_shape, num_classes):\n",
    "    \"\"\"Creates an instance of a multi-layer perceptron model.\n",
    "    # Arguments\n",
    "        layers: int, number of `Dense` layers in the model.\n",
    "        units: int, output dimension of the layers.\n",
    "        dropout_rate: float, percentage of input to drop at Dropout layers.\n",
    "        input_shape: tuple, shape of input to the model.\n",
    "        num_classes: int, number of output classes.\n",
    "    # Returns\n",
    "        An MLP model instance.\n",
    "    \"\"\"\n",
    "    op_units, op_activation = _get_last_layer_units_and_activation(num_classes)\n",
    "    model = models.Sequential()\n",
    "    model.add(Dropout(rate=dropout_rate, input_shape=input_shape))\n",
    "\n",
    "    for _ in range(layers-1):\n",
    "        model.add(Dense(units=units, activation='relu'))\n",
    "        model.add(Dropout(rate=dropout_rate))\n",
    "\n",
    "    model.add(Dense(units=op_units, activation=op_activation))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F68CwZ8Oy5SW"
   },
   "source": [
    "Build and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 236,
     "status": "ok",
     "timestamp": 1643693372789,
     "user": {
      "displayName": "Dave Williford",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg1oB0_dFMci-8J9hCWjfFgiRe6DHGeTdAG7OWf2A=s64",
      "userId": "07870752706515771222"
     },
     "user_tz": 480
    },
    "id": "MLspIYr7hVNQ"
   },
   "outputs": [],
   "source": [
    "def get_num_classes(labels):\n",
    "    \"\"\"Gets the total number of classes.\n",
    "    # Arguments\n",
    "        labels: list, label values.\n",
    "            There should be at lease one sample for values in the\n",
    "            range (0, num_classes -1)\n",
    "    # Returns\n",
    "        int, total number of classes.\n",
    "    # Raises\n",
    "        ValueError: if any label value in the range(0, num_classes - 1)\n",
    "            is missing or if number of classes is <= 1.\n",
    "    \"\"\"\n",
    "    num_classes = max(labels) + 1\n",
    "    missing_classes = [i for i in range(num_classes) if i not in labels]\n",
    "    if len(missing_classes):\n",
    "        raise ValueError('Missing samples with label value(s) '\n",
    "                         '{missing_classes}. Please make sure you have '\n",
    "                         'at least one sample for every label value '\n",
    "                         'in the range(0, {max_class})'.format(\n",
    "                            missing_classes=missing_classes,\n",
    "                            max_class=num_classes - 1))\n",
    "\n",
    "    if num_classes <= 1:\n",
    "        raise ValueError('Invalid number of labels: {num_classes}.'\n",
    "                         'Please make sure there are at least two classes '\n",
    "                         'of samples'.format(num_classes=num_classes))\n",
    "    return num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 291,
     "status": "ok",
     "timestamp": 1643693375558,
     "user": {
      "displayName": "Dave Williford",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg1oB0_dFMci-8J9hCWjfFgiRe6DHGeTdAG7OWf2A=s64",
      "userId": "07870752706515771222"
     },
     "user_tz": 480
    },
    "id": "1BgJHXieorid"
   },
   "outputs": [],
   "source": [
    "\"\"\"Module to train n-gram model.\n",
    "\n",
    "Vectorizes training and validation texts into n-grams and uses that for\n",
    "training a n-gram model - a simple multi-layer perceptron model. We use n-gram\n",
    "model for text classification when the ratio of number of samples to number of\n",
    "words per sample for the given dataset is very small (<~1500).\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "FLAGS = None\n",
    "\n",
    "\n",
    "def train_ngram_model(data,\n",
    "                      learning_rate=1e-3,\n",
    "                      epochs=1000,\n",
    "                      batch_size=128,\n",
    "                      layers=2,\n",
    "                      units=64,\n",
    "                      dropout_rate=0.2):\n",
    "    \"\"\"Trains n-gram model on the given dataset.\n",
    "\n",
    "    # Arguments\n",
    "        data: tuples of training and test texts and labels.\n",
    "        learning_rate: float, learning rate for training model.\n",
    "        epochs: int, number of epochs.\n",
    "        batch_size: int, number of samples per batch.\n",
    "        layers: int, number of `Dense` layers in the model.\n",
    "        units: int, output dimension of Dense layers in the model.\n",
    "        dropout_rate: float: percentage of input to drop at Dropout layers.\n",
    "\n",
    "    # Raises\n",
    "        ValueError: If validation data has label values which were not seen\n",
    "            in the training data.\n",
    "    \"\"\"\n",
    "    # Get the data.\n",
    "    (train_texts, train_labels), (val_texts, val_labels) = data\n",
    "\n",
    "    # Verify that validation labels are in the same range as training labels.\n",
    "    num_classes = get_num_classes(train_labels)\n",
    "    unexpected_labels = [v for v in val_labels if v not in range(num_classes)]\n",
    "    if len(unexpected_labels):\n",
    "        raise ValueError('Unexpected label values found in the validation set:'\n",
    "                         ' {unexpected_labels}. Please make sure that the '\n",
    "                         'labels in the validation set are in the same range '\n",
    "                         'as training labels.'.format(\n",
    "                             unexpected_labels=unexpected_labels))\n",
    "\n",
    "    # Vectorize texts.\n",
    "    #x_train, x_val = vectorize_data.ngram_vectorize(\n",
    "    x_train, x_val = ngram_vectorize(\n",
    "        train_texts, train_labels, val_texts)\n",
    "\n",
    "    # Create model instance.\n",
    "    #model = build_model.mlp_model(layers=layers,\n",
    "    model = mlp_model(layers=layers,\n",
    "                                  units=units,\n",
    "                                  dropout_rate=dropout_rate,\n",
    "                                  input_shape=x_train.shape[1:],\n",
    "                                  num_classes=num_classes)\n",
    "\n",
    "    \n",
    "    # Compile model with learning parameters.\n",
    "    if num_classes == 2:\n",
    "        loss = 'binary_crossentropy'\n",
    "    else:\n",
    "        loss = 'sparse_categorical_crossentropy'\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=['acc'])\n",
    "\n",
    "    # Create callback for early stopping on validation loss. If the loss does\n",
    "    # not decrease in two consecutive tries, stop training.\n",
    "    callbacks = [tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', patience=3)]\n",
    "\n",
    "    # Train and validate model.\n",
    "    history = model.fit(\n",
    "            x_train,\n",
    "            train_labels,\n",
    "            epochs=epochs,\n",
    "            callbacks=callbacks,\n",
    "            validation_data=(x_val, val_labels),\n",
    "            verbose=2,  # Logs once per epoch.\n",
    "            batch_size=batch_size)\n",
    "\n",
    "    # Print results.\n",
    "    history = history.history\n",
    "    print('Validation accuracy: {acc}, loss: {loss}'.format(\n",
    "            acc=history['val_acc'][-1], loss=history['val_loss'][-1]))\n",
    "\n",
    "    # Save model.\n",
    "    model.save('devo_classification_mlp_model.h5')\n",
    "    return history['val_acc'][-1], history['val_loss'][-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oPp4FHSEgIZ6",
    "outputId": "32750b94-89be-4c46-d3a2-11be7c785477"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dave\\anaconda3\\envs\\CudaPython\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:2032: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. int32 'dtype' will be converted to np.float64.\n",
      "  UserWarning,\n",
      "C:\\Users\\Dave\\anaconda3\\envs\\CudaPython\\lib\\site-packages\\sklearn\\utils\\validation.py:590: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  FutureWarning,\n",
      "C:\\Users\\Dave\\anaconda3\\envs\\CudaPython\\lib\\site-packages\\sklearn\\utils\\validation.py:590: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  FutureWarning,\n",
      "C:\\Users\\Dave\\anaconda3\\envs\\CudaPython\\lib\\site-packages\\sklearn\\utils\\validation.py:590: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "42/42 - 1s - loss: 1.5722 - acc: 0.3465 - val_loss: 1.5348 - val_acc: 0.3647\n",
      "Epoch 2/1000\n",
      "42/42 - 0s - loss: 1.4234 - acc: 0.5374 - val_loss: 1.4217 - val_acc: 0.4932\n",
      "Epoch 3/1000\n",
      "42/42 - 0s - loss: 1.2181 - acc: 0.7287 - val_loss: 1.2987 - val_acc: 0.5636\n",
      "Epoch 4/1000\n",
      "42/42 - 0s - loss: 0.9994 - acc: 0.8148 - val_loss: 1.1977 - val_acc: 0.5768\n",
      "Epoch 5/1000\n",
      "42/42 - 0s - loss: 0.8140 - acc: 0.8596 - val_loss: 1.1267 - val_acc: 0.5908\n",
      "Epoch 6/1000\n",
      "42/42 - 0s - loss: 0.6645 - acc: 0.8812 - val_loss: 1.0818 - val_acc: 0.5970\n",
      "Epoch 7/1000\n",
      "42/42 - 0s - loss: 0.5431 - acc: 0.9047 - val_loss: 1.0468 - val_acc: 0.6058\n",
      "Epoch 8/1000\n",
      "42/42 - 0s - loss: 0.4531 - acc: 0.9249 - val_loss: 1.0257 - val_acc: 0.6076\n",
      "Epoch 9/1000\n",
      "42/42 - 0s - loss: 0.3812 - acc: 0.9345 - val_loss: 1.0148 - val_acc: 0.6054\n",
      "Epoch 10/1000\n",
      "42/42 - 0s - loss: 0.3204 - acc: 0.9536 - val_loss: 1.0062 - val_acc: 0.6146\n",
      "Epoch 11/1000\n",
      "42/42 - 0s - loss: 0.2807 - acc: 0.9598 - val_loss: 1.0021 - val_acc: 0.6128\n",
      "Epoch 12/1000\n",
      "42/42 - 0s - loss: 0.2411 - acc: 0.9651 - val_loss: 1.0019 - val_acc: 0.6155\n",
      "Epoch 13/1000\n",
      "42/42 - 0s - loss: 0.2097 - acc: 0.9721 - val_loss: 1.0025 - val_acc: 0.6159\n",
      "Epoch 14/1000\n",
      "42/42 - 0s - loss: 0.1859 - acc: 0.9772 - val_loss: 1.0084 - val_acc: 0.6159\n",
      "Validation accuracy: 0.6159260869026184, loss: 1.0084409713745117\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6159260869026184, 1.0084409713745117)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With early stop 2\n",
    "data = [(train_texts, train_labels), (val_texts, val_labels)]\n",
    "train_ngram_model(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 154,
     "status": "ok",
     "timestamp": 1643690104187,
     "user": {
      "displayName": "Dave Williford",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg1oB0_dFMci-8J9hCWjfFgiRe6DHGeTdAG7OWf2A=s64",
      "userId": "07870752706515771222"
     },
     "user_tz": 480
    },
    "id": "Q2ghE3twkGl-",
    "outputId": "900c3bc8-22b6-4680-ddc9-8c220d23cfb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "42jB7fC_uT7g"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "def print_report(y_test,y_pred):\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "    print('\\nAccuracy: ', accuracy_score(y_test, y_pred))\n",
    "    print('\\n', class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from joblib import parallel_backend\n",
    "import joblib\n",
    "def cv_optimize(clf, parameters, X_train, y_train, n_folds=5):\n",
    "    gs = GridSearchCV(clf, param_grid=parameters, cv=n_folds)\n",
    "    gs.fit(X_train, y_train)\n",
    "    print(\"Optimal params: \" + str(gs.best_params_))\n",
    "    return gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dave\\anaconda3\\envs\\CudaPython\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:2032: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. int32 'dtype' will be converted to np.float64.\n",
      "  UserWarning,\n",
      "C:\\Users\\Dave\\anaconda3\\envs\\CudaPython\\lib\\site-packages\\sklearn\\utils\\validation.py:590: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  FutureWarning,\n",
      "C:\\Users\\Dave\\anaconda3\\envs\\CudaPython\\lib\\site-packages\\sklearn\\utils\\validation.py:590: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  FutureWarning,\n",
      "C:\\Users\\Dave\\anaconda3\\envs\\CudaPython\\lib\\site-packages\\sklearn\\utils\\validation.py:590: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy:  0.2833260008798944\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.05      0.09       365\n",
      "           1       0.26      0.99      0.41       568\n",
      "           2       0.94      0.03      0.07       435\n",
      "           3       0.91      0.02      0.05       423\n",
      "           4       0.72      0.07      0.14       482\n",
      "\n",
      "    accuracy                           0.28      2273\n",
      "   macro avg       0.75      0.24      0.15      2273\n",
      "weighted avg       0.71      0.28      0.17      2273\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from joblib import parallel_backend\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier(n_neighbors=11)\n",
    "\n",
    "#data = [(train_texts, train_labels), (val_texts, val_labels)]\n",
    "\n",
    "with parallel_backend('threading', n_jobs=-1):\n",
    "    x_train, x_val = ngram_vectorize(train_texts, train_labels, val_texts)\n",
    "    clf.fit(x_train, train_labels)\n",
    "    y_pred = clf.predict(x_val)\n",
    "\n",
    "print_report(val_labels,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dave\\anaconda3\\envs\\CudaPython\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:2032: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. int32 'dtype' will be converted to np.float64.\n",
      "  UserWarning,\n",
      "C:\\Users\\Dave\\anaconda3\\envs\\CudaPython\\lib\\site-packages\\sklearn\\utils\\validation.py:590: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  FutureWarning,\n",
      "C:\\Users\\Dave\\anaconda3\\envs\\CudaPython\\lib\\site-packages\\sklearn\\utils\\validation.py:590: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  FutureWarning,\n",
      "C:\\Users\\Dave\\anaconda3\\envs\\CudaPython\\lib\\site-packages\\sklearn\\utils\\validation.py:590: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal params: {'n_neighbors': 1}\n",
      "\n",
      "Accuracy:  0.33040035195776507\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.13      0.23       365\n",
      "           1       0.28      0.94      0.43       568\n",
      "           2       0.53      0.11      0.19       435\n",
      "           3       0.63      0.12      0.20       423\n",
      "           4       0.67      0.14      0.24       482\n",
      "\n",
      "    accuracy                           0.33      2273\n",
      "   macro avg       0.58      0.29      0.25      2273\n",
      "weighted avg       0.56      0.33      0.27      2273\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier()\n",
    "parameters = {\"n_neighbors\": range(1,40,5) }\n",
    "with parallel_backend('threading', n_jobs=-1):\n",
    "    x_train, x_val = ngram_vectorize(train_texts, train_labels, val_texts)\n",
    "    clf = cv_optimize(clf, parameters, x_train, train_labels)\n",
    "    clf.fit(x_train, train_labels)\n",
    "    y_pred = clf.predict(x_val)\n",
    "\n",
    "print_report(val_labels,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dave\\anaconda3\\envs\\CudaPython\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:2032: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. int32 'dtype' will be converted to np.float64.\n",
      "  UserWarning,\n",
      "C:\\Users\\Dave\\anaconda3\\envs\\CudaPython\\lib\\site-packages\\sklearn\\utils\\validation.py:590: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  FutureWarning,\n",
      "C:\\Users\\Dave\\anaconda3\\envs\\CudaPython\\lib\\site-packages\\sklearn\\utils\\validation.py:590: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  FutureWarning,\n",
      "C:\\Users\\Dave\\anaconda3\\envs\\CudaPython\\lib\\site-packages\\sklearn\\utils\\validation.py:590: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "42/42 - 1s - loss: 1.5707 - acc: 0.3496 - val_loss: 1.5297 - val_acc: 0.3704\n",
      "Epoch 2/1000\n",
      "42/42 - 0s - loss: 1.4157 - acc: 0.5695 - val_loss: 1.4128 - val_acc: 0.5029\n",
      "Epoch 3/1000\n",
      "42/42 - 0s - loss: 1.2077 - acc: 0.7295 - val_loss: 1.2921 - val_acc: 0.5517\n",
      "Epoch 4/1000\n",
      "42/42 - 0s - loss: 0.9903 - acc: 0.8214 - val_loss: 1.1902 - val_acc: 0.5856\n",
      "Epoch 5/1000\n",
      "42/42 - 0s - loss: 0.8087 - acc: 0.8563 - val_loss: 1.1202 - val_acc: 0.5904\n",
      "Epoch 6/1000\n",
      "42/42 - 0s - loss: 0.6548 - acc: 0.8817 - val_loss: 1.0723 - val_acc: 0.6027\n",
      "Epoch 7/1000\n",
      "42/42 - 0s - loss: 0.5417 - acc: 0.9085 - val_loss: 1.0426 - val_acc: 0.6014\n",
      "Epoch 8/1000\n",
      "42/42 - 0s - loss: 0.4489 - acc: 0.9245 - val_loss: 1.0247 - val_acc: 0.6023\n",
      "Epoch 9/1000\n",
      "42/42 - 0s - loss: 0.3763 - acc: 0.9396 - val_loss: 1.0087 - val_acc: 0.6106\n",
      "Epoch 10/1000\n",
      "42/42 - 0s - loss: 0.3222 - acc: 0.9562 - val_loss: 0.9974 - val_acc: 0.6150\n",
      "Epoch 11/1000\n",
      "42/42 - 0s - loss: 0.2743 - acc: 0.9630 - val_loss: 0.9928 - val_acc: 0.6168\n",
      "Epoch 12/1000\n",
      "42/42 - 0s - loss: 0.2406 - acc: 0.9676 - val_loss: 0.9927 - val_acc: 0.6150\n",
      "Epoch 13/1000\n",
      "42/42 - 0s - loss: 0.2066 - acc: 0.9713 - val_loss: 0.9952 - val_acc: 0.6146\n",
      "Epoch 14/1000\n",
      "42/42 - 0s - loss: 0.1858 - acc: 0.9764 - val_loss: 0.9986 - val_acc: 0.6120\n",
      "Validation accuracy: 0.6119665503501892, loss: 0.9986212849617004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6119665503501892, 0.9986212849617004)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With early stop 3\n",
    "data = [(train_texts, train_labels), (val_texts, val_labels)]\n",
    "train_ngram_model(data)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMQinPxET0W6wN8X6dv/ISl",
   "collapsed_sections": [],
   "name": "Text_Classification_MLP.ipynb",
   "provenance": [
    {
     "file_id": "1S6iIjW8JgLqZo3eYTKeyhlT4zZa4kai5",
     "timestamp": 1643691099955
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
